{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emrekuru/Developer/Finance_RAG/.venv/lib/python3.12/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from pinecone import Pinecone\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from main import VectorDatabase, BiEncoder, CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiliaze Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\n",
      "    \"name\": \"finbert\",\n",
      "    \"dimension\": 768,\n",
      "    \"metric\": \"dotproduct\",\n",
      "    \"host\": \"finbert-im26dq4.svc.aped-4627-b74a.pinecone.io\",\n",
      "    \"spec\": {\n",
      "        \"serverless\": {\n",
      "            \"cloud\": \"aws\",\n",
      "            \"region\": \"us-east-1\"\n",
      "        }\n",
      "    },\n",
      "    \"status\": {\n",
      "        \"ready\": true,\n",
      "        \"state\": \"Ready\"\n",
      "    },\n",
      "    \"deletion_protection\": \"disabled\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "API_KEY = \"c4ac140e-932e-40c3-84e5-e407580eef2a\"\n",
    "pc = Pinecone(api_key=API_KEY)\n",
    "indexes = pc.list_indexes()\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = 'finbert'\n",
    "DIMENSION = 768 \n",
    "CLOUD = 'aws'\n",
    "REGION = 'us-west-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = VectorDatabase(api_key=API_KEY)\n",
    "handler = vector_db.start_db(index_name=INDEX_NAME, dimension=DIMENSION, cloud=CLOUD, region=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Related Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>q00001</th>\n",
       "      <td>What are the service and product offerings fro...</td>\n",
       "      <td>['MSFT20230014', 'MSFT20230015']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00002</th>\n",
       "      <td>MSFT segment breakdown</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00003</th>\n",
       "      <td>Who are Microsoft`s key customers?</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00004</th>\n",
       "      <td>What is Microsoft`s business model</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00005</th>\n",
       "      <td>MSFT Capex commitment</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00214</th>\n",
       "      <td>How many distinct insurance underwriting group...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00215</th>\n",
       "      <td>What is the ticker symbol for Berkshire Hathaw...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00216</th>\n",
       "      <td>What is the largest operating segment of the B...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00217</th>\n",
       "      <td>Source of invested assets of insurance busines...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00218</th>\n",
       "      <td>Float as of 2023 BRK</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "q00001  What are the service and product offerings fro...   \n",
       "q00002                             MSFT segment breakdown   \n",
       "q00003                 Who are Microsoft`s key customers?   \n",
       "q00004                 What is Microsoft`s business model   \n",
       "q00005                              MSFT Capex commitment   \n",
       "...                                                   ...   \n",
       "q00214  How many distinct insurance underwriting group...   \n",
       "q00215  What is the ticker symbol for Berkshire Hathaw...   \n",
       "q00216  What is the largest operating segment of the B...   \n",
       "q00217  Source of invested assets of insurance busines...   \n",
       "q00218                               Float as of 2023 BRK   \n",
       "\n",
       "                       Related Documents  \n",
       "q00001  ['MSFT20230014', 'MSFT20230015']  \n",
       "q00002                                []  \n",
       "q00003                                []  \n",
       "q00004                                []  \n",
       "q00005                                []  \n",
       "...                                  ...  \n",
       "q00214                                []  \n",
       "q00215                                []  \n",
       "q00216                                []  \n",
       "q00217                                []  \n",
       "q00218                                []  \n",
       "\n",
       "[216 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder_path = os.path.join('..', 'data')\n",
    "query_df = pd.read_csv(os.path.join(data_folder_path, \"FinDER/queries.csv\"), index_col=0)\n",
    "document_df = pd.read_csv(os.path.join(data_folder_path, \"FinDER/corpus.csv\"), index_col=0)\n",
    "query_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed Documents and Save to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_documents = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('ProsusAI/finbert')\n",
    "model = AutoModel.from_pretrained('ProsusAI/finbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = BiEncoder(tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_df[\"text\"] = document_df[\"text\"].fillna(\"\") \n",
    "texts = document_df[\"text\"].astype(str).tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if embed_documents:\n",
    "        handler.delete_all()\n",
    "except:\n",
    "    print(\"No data in index to delete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if embed_documents:\n",
    "\n",
    "    batch_size = 100  \n",
    "    document_df[\"text\"] = document_df[\"text\"].fillna(\"\")\n",
    "    document_df[\"title\"] = document_df[\"title\"].fillna(\"\")\n",
    "    texts = document_df[\"text\"].astype(str).tolist()\n",
    "    titles = document_df[\"title\"].astype(str).tolist()\n",
    "\n",
    "    # Should be len(texts) in the final version\n",
    "    limit = len(texts)\n",
    "\n",
    "    def batch_upsert(titles, texts, batch_size):\n",
    "        # Iterate through batches of texts and titles\n",
    "        for i in range(0, limit, batch_size):\n",
    "            try:\n",
    "                batch_texts = texts[i:i+batch_size]\n",
    "                batch_titles = titles[i:i+batch_size]\n",
    "                batch_indexes = document_df.index[i:i+batch_size]\n",
    "\n",
    "                # Encode the titles and texts separately\n",
    "                encoded_titles = encoder.encode_batch(batch_titles)\n",
    "                encoded_texts = encoder.encode_batch(batch_texts)\n",
    "\n",
    "                # Mean pooling: element-wise mean of title and text embeddings\n",
    "                pooled_embeddings = (encoded_titles + encoded_texts) / 2.0\n",
    "\n",
    "                # Prepare the batch data for upsert\n",
    "                batch_data = [(str(idx), embedding.tolist()) for idx, embedding in zip(batch_indexes, pooled_embeddings)]\n",
    "\n",
    "                # Perform batch upsert\n",
    "                handler.index.upsert(vectors=batch_data)\n",
    "                print(f\"Upserted batch {i//batch_size + 1}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "    # Call the function with both titles and texts\n",
    "    batch_upsert(titles, texts, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>q00001</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00002</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00003</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00004</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00005</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00214</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00215</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00216</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00217</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00218</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Documents\n",
       "q00001        []\n",
       "q00002        []\n",
       "q00003        []\n",
       "q00004        []\n",
       "q00005        []\n",
       "...          ...\n",
       "q00214        []\n",
       "q00215        []\n",
       "q00216        []\n",
       "q00217        []\n",
       "q00218        []\n",
       "\n",
       "[216 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_df = pd.DataFrame([[[] ] for _ in query_df.index], index=query_df.index, columns=[\"Documents\"])\n",
    "retrieved_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in query_df.iterrows():\n",
    "    query = row[\"text\"]\n",
    "    query = encoder.encode(query)\n",
    "    query = np.array(query, dtype=np.float32)\n",
    "\n",
    "    query_list = query.tolist()\n",
    "\n",
    "    results = handler.query_vector(query_list, top_k=20)\n",
    "    retrieved_df.at[idx, \"Documents\"] = [ result[\"id\"] for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>q00001</th>\n",
       "      <td>[ADBE20230209, BRK.A20230330, ADBE20230173, AD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00002</th>\n",
       "      <td>[ADBE20231062, TSLA20230439, TSLA20230008, TSL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00003</th>\n",
       "      <td>[GOOGL20230652, ORCL20231713, MSFT20230446, MS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00004</th>\n",
       "      <td>[LIN20231708, CPNG20231083, BRK.A20230330, PG2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00005</th>\n",
       "      <td>[MSFT20230430, MSFT20230429, ADBE20230975, NVD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00214</th>\n",
       "      <td>[MSFT20230238, ADBE20231055, PG20230206, MSFT2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00215</th>\n",
       "      <td>[MSFT20230446, TSLA20231571, ADBE20231748, DAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00216</th>\n",
       "      <td>[ORCL20230433, NFLX20230009, AMZN20231245, TSL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00217</th>\n",
       "      <td>[BRK.A20230463, BRK.A20230080, BRK.A20230089, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00218</th>\n",
       "      <td>[MSFT20231704, MSFT20230446, LIN20231722, AMZN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Documents\n",
       "q00001  [ADBE20230209, BRK.A20230330, ADBE20230173, AD...\n",
       "q00002  [ADBE20231062, TSLA20230439, TSLA20230008, TSL...\n",
       "q00003  [GOOGL20230652, ORCL20231713, MSFT20230446, MS...\n",
       "q00004  [LIN20231708, CPNG20231083, BRK.A20230330, PG2...\n",
       "q00005  [MSFT20230430, MSFT20230429, ADBE20230975, NVD...\n",
       "...                                                   ...\n",
       "q00214  [MSFT20230238, ADBE20231055, PG20230206, MSFT2...\n",
       "q00215  [MSFT20230446, TSLA20231571, ADBE20231748, DAL...\n",
       "q00216  [ORCL20230433, NFLX20230009, AMZN20231245, TSL...\n",
       "q00217  [BRK.A20230463, BRK.A20230080, BRK.A20230089, ...\n",
       "q00218  [MSFT20231704, MSFT20230446, LIN20231722, AMZN...\n",
       "\n",
       "[216 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('ProsusAI/finbert')\n",
    "model = AutoModel.from_pretrained('ProsusAI/finbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_encoder = CrossEncoder(tokenizer=tokenizer,model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for contrastive learning with positive and negative document sampling.\n",
    "    \"\"\"\n",
    "    def __init__(self, queries, document_dict, related_docs, all_documents):\n",
    "        # Filter out queries without positive examples\n",
    "        self.queries = [q for q, rel_docs in zip(queries, related_docs) if len(rel_docs) > 0]\n",
    "        self.related_docs = [rel_docs for rel_docs in related_docs if len(rel_docs) > 0]\n",
    "        \n",
    "        self.document_dict = document_dict  # Maps doc IDs to actual texts\n",
    "        self.all_documents = all_documents  # List of all document IDs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        query = self.queries[idx]\n",
    "        positive_doc_ids = self.related_docs[idx]\n",
    "\n",
    "        # Select a random positive document from the related documents\n",
    "        positive_doc_id = random.choice(positive_doc_ids)\n",
    "        positive_doc = self.document_dict[positive_doc_id]\n",
    "        \n",
    "        # Sample a negative document ID from the rest of the documents\n",
    "        negative_doc_id = random.choice([doc for doc in self.all_documents if doc not in positive_doc_ids])\n",
    "        negative_doc = self.document_dict[negative_doc_id]\n",
    "        \n",
    "        return query, positive_doc, negative_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(query_embeddings, positive_doc_embeddings, negative_doc_embeddings, temperature=0.07):\n",
    "    # Cosine similarity between query and positive/negative document pairs\n",
    "    pos_sim = F.cosine_similarity(query_embeddings, positive_doc_embeddings)\n",
    "    neg_sim = F.cosine_similarity(query_embeddings, negative_doc_embeddings)\n",
    "    \n",
    "    # Compute the InfoNCE-like loss\n",
    "    pos_exp = torch.exp(pos_sim / temperature)\n",
    "    neg_exp = torch.exp(neg_sim / temperature)\n",
    "    \n",
    "    # Contrastive loss: encourage similarity with positive, discourage with negative\n",
    "    loss = -torch.log(pos_exp / (pos_exp + neg_exp))\n",
    "    \n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune(encoder: CrossEncoder, dataset, epochs=3, batch_size=8, learning_rate=1e-5, temperature=0.07):\n",
    "\n",
    "    # Create a DataLoader for the dataset\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Define optimizer\n",
    "    optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    encoder.train() \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            queries, positive_docs, negative_docs = batch\n",
    "            \n",
    "            optimizer.zero_grad()  # Zero the gradients\n",
    "            \n",
    "            # Encode the queries and corresponding documents\n",
    "            query_embeddings = torch.stack([encoder.encode(query, query) for query in queries])\n",
    "            positive_doc_embeddings = torch.stack([encoder.encode(query, doc) for query, doc in zip(queries, positive_docs)])\n",
    "            negative_doc_embeddings = torch.stack([encoder.encode(query, doc) for query, doc in zip(queries, negative_docs)])\n",
    "            \n",
    "            # Compute the contrastive loss\n",
    "            loss = contrastive_loss(query_embeddings, positive_doc_embeddings, negative_doc_embeddings, temperature)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Backpropagate and update model parameters\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Print the loss for each epoch\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(data_loader)}\")\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 1.2426532544195652\n",
      "Epoch [2/3], Loss: 0.6164814867079258\n",
      "Epoch [3/3], Loss: 0.4872545227408409\n"
     ]
    }
   ],
   "source": [
    "dataset = ContrastiveDataset(query_df[\"text\"], document_df[\"text\"].to_dict(), query_df[\"Related Documents\"].apply(ast.literal_eval),  document_df.index)\n",
    "cross_encoder = fine_tune(cross_encoder, dataset, epochs=3, batch_size=8, learning_rate=1e-5, temperature=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(embedding_a, embedding_b):\n",
    "    return F.cosine_similarity(embedding_a.unsqueeze(0), embedding_b.unsqueeze(0)).item()\n",
    "\n",
    "def rerank_documents(encoder, query, documents, top_k=5):\n",
    "    # Generate query embedding\n",
    "    query_embedding = encoder.encode(query, query)\n",
    "    \n",
    "    # List to store document IDs and their cosine similarity scores\n",
    "    ranked_results = []\n",
    "\n",
    "    # Loop through each document and compute the cosine similarity score\n",
    "    for doc_id in documents:\n",
    "        document_text = document_df.loc[doc_id, 'text']  \n",
    "        document_embedding = encoder.encode(query, document_text)\n",
    "        similarity_score = compute_cosine_similarity(query_embedding, document_embedding)\n",
    "        ranked_results.append((doc_id, similarity_score))\n",
    "\n",
    "    # Sort the documents by cosine similarity score in descending order\n",
    "    ranked_results = sorted(ranked_results, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Keep only the top-k documents\n",
    "    top_k_documents = [doc_id for doc_id, score in ranked_results[:top_k]]\n",
    "    \n",
    "    return top_k_documents\n",
    "\n",
    "for idx, row in query_df.iterrows():\n",
    "    query = row[\"text\"]\n",
    "    related_docs = retrieved_df.at[idx, \"Documents\"]\n",
    "    reranked_docs = rerank_documents(cross_encoder, query, related_docs, top_k=3)\n",
    "    retrieved_df.at[idx, \"Documents\"] = reranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>q00001</th>\n",
       "      <td>[NVDA20230430, MSFT20231710, MSFT20230975]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00002</th>\n",
       "      <td>[TSLA20230439, ADBE20230975, LIN20230371]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00003</th>\n",
       "      <td>[GOOGL20230652, NVDA20230140, ADBE20231748]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00004</th>\n",
       "      <td>[PG20231472, MSFT20231788, PG20230011]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00005</th>\n",
       "      <td>[GOOGL20230760, ADBE20230986, ADBE20231131]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00214</th>\n",
       "      <td>[PG20230206, MSFT20231865, TSLA20230007]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00215</th>\n",
       "      <td>[MSFT20230446, NFLX20230219, NVDA20230979]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00216</th>\n",
       "      <td>[ORCL20230433, BRK.A20230715, TSLA20230439]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00217</th>\n",
       "      <td>[NVDA20230395, TSLA20230886, BRK.A20230080]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00218</th>\n",
       "      <td>[CPNG20231602, AMZN20231148, DAL20231744]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Documents\n",
       "q00001   [NVDA20230430, MSFT20231710, MSFT20230975]\n",
       "q00002    [TSLA20230439, ADBE20230975, LIN20230371]\n",
       "q00003  [GOOGL20230652, NVDA20230140, ADBE20231748]\n",
       "q00004       [PG20231472, MSFT20231788, PG20230011]\n",
       "q00005  [GOOGL20230760, ADBE20230986, ADBE20231131]\n",
       "...                                             ...\n",
       "q00214     [PG20230206, MSFT20231865, TSLA20230007]\n",
       "q00215   [MSFT20230446, NFLX20230219, NVDA20230979]\n",
       "q00216  [ORCL20230433, BRK.A20230715, TSLA20230439]\n",
       "q00217  [NVDA20230395, TSLA20230886, BRK.A20230080]\n",
       "q00218    [CPNG20231602, AMZN20231148, DAL20231744]\n",
       "\n",
       "[216 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retrieval(actual_related_ids, retrieved_docs_ids, top_k=None):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    for actual_ids, retrieved_ids in zip(actual_related_ids, retrieved_docs_ids):\n",
    "        if top_k:\n",
    "            retrieved_ids = retrieved_ids[:top_k]\n",
    "        \n",
    "        actual_set = set(actual_ids)\n",
    "        retrieved_set = set(retrieved_ids)\n",
    "        \n",
    "        true_positives = len(actual_set & retrieved_set)\n",
    "        precision = true_positives / len(retrieved_set) if retrieved_set else 0\n",
    "        recall = true_positives / len(actual_set) if actual_set else 0\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    avg_precision = sum(precisions) / len(precisions) if precisions else 0\n",
    "    avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
    "    \n",
    "    avg_f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n",
    "    \n",
    "    return avg_precision, avg_recall, avg_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_retrieval(query_df[\"Related Documents\"], retrieved_df[\"Documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Related Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>q00001</th>\n",
       "      <td>What are the service and product offerings fro...</td>\n",
       "      <td>['MSFT20230014', 'MSFT20230015']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00007</th>\n",
       "      <td>How much revenue does Microsoft generate from ...</td>\n",
       "      <td>['MSFT20231529']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00008</th>\n",
       "      <td>MSFT remaining performance obligation</td>\n",
       "      <td>['MSFT20231529']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00010</th>\n",
       "      <td>ADBE share repurchase</td>\n",
       "      <td>['ADBE20231571', 'ADBE20231572', 'ADBE20230728...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00019</th>\n",
       "      <td>When did Coupang`s Farfetch consolidation start</td>\n",
       "      <td>['CPNG20230732']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00197</th>\n",
       "      <td>What factors contributed to the significant in...</td>\n",
       "      <td>['UNH20230432', 'UNH20230433', 'UNH20230436', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00200</th>\n",
       "      <td>Primary revenue source of Google Services</td>\n",
       "      <td>['GOOGL20230050']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00204</th>\n",
       "      <td>Capex guidance Alphabet</td>\n",
       "      <td>['GOOGL20230680']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00210</th>\n",
       "      <td>Who runs berkshire</td>\n",
       "      <td>['BRK.A20230396']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00212</th>\n",
       "      <td>How is Berkshire Hathaway`s business segmented...</td>\n",
       "      <td>['BRK.A20232388']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "q00001  What are the service and product offerings fro...   \n",
       "q00007  How much revenue does Microsoft generate from ...   \n",
       "q00008              MSFT remaining performance obligation   \n",
       "q00010                              ADBE share repurchase   \n",
       "q00019    When did Coupang`s Farfetch consolidation start   \n",
       "...                                                   ...   \n",
       "q00197  What factors contributed to the significant in...   \n",
       "q00200          Primary revenue source of Google Services   \n",
       "q00204                            Capex guidance Alphabet   \n",
       "q00210                                 Who runs berkshire   \n",
       "q00212  How is Berkshire Hathaway`s business segmented...   \n",
       "\n",
       "                                        Related Documents  \n",
       "q00001                   ['MSFT20230014', 'MSFT20230015']  \n",
       "q00007                                   ['MSFT20231529']  \n",
       "q00008                                   ['MSFT20231529']  \n",
       "q00010  ['ADBE20231571', 'ADBE20231572', 'ADBE20230728...  \n",
       "q00019                                   ['CPNG20230732']  \n",
       "...                                                   ...  \n",
       "q00197  ['UNH20230432', 'UNH20230433', 'UNH20230436', ...  \n",
       "q00200                                  ['GOOGL20230050']  \n",
       "q00204                                  ['GOOGL20230680']  \n",
       "q00210                                  ['BRK.A20230396']  \n",
       "q00212                                  ['BRK.A20232388']  \n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_empty = query_df[query_df[\"Related Documents\"].apply(lambda x: len(ast.literal_eval(x)) > 0)]\n",
    "index = non_empty.index\n",
    "non_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>q00001</th>\n",
       "      <td>[NVDA20230430, MSFT20231710, MSFT20230975]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00007</th>\n",
       "      <td>[AMZN20230018, ADBE20230055, ORCL20230115]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00008</th>\n",
       "      <td>[BRK.A20230905, BRK.A20230426, ADBE20231289]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00010</th>\n",
       "      <td>[GOOGL20231589, TSLA20230886, GOOGL20230698]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00019</th>\n",
       "      <td>[GOOGL20230652, ADBE20231131, ORCL20231909]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00197</th>\n",
       "      <td>[MSFT20231048, TSLA20230097, MSFT20230059]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00200</th>\n",
       "      <td>[GOOGL20230565, ADBE20230975, TSLA20230841]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00204</th>\n",
       "      <td>[NFLX20230502, DAL20231891, MSFT20231710]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00210</th>\n",
       "      <td>[ORCL20231907, TSLA20230569, AMZN20230531]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q00212</th>\n",
       "      <td>[ADBE20231055, BRK.A20230330, PG20230206]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Documents\n",
       "q00001    [NVDA20230430, MSFT20231710, MSFT20230975]\n",
       "q00007    [AMZN20230018, ADBE20230055, ORCL20230115]\n",
       "q00008  [BRK.A20230905, BRK.A20230426, ADBE20231289]\n",
       "q00010  [GOOGL20231589, TSLA20230886, GOOGL20230698]\n",
       "q00019   [GOOGL20230652, ADBE20231131, ORCL20231909]\n",
       "...                                              ...\n",
       "q00197    [MSFT20231048, TSLA20230097, MSFT20230059]\n",
       "q00200   [GOOGL20230565, ADBE20230975, TSLA20230841]\n",
       "q00204     [NFLX20230502, DAL20231891, MSFT20231710]\n",
       "q00210    [ORCL20231907, TSLA20230569, AMZN20230531]\n",
       "q00212     [ADBE20231055, BRK.A20230330, PG20230206]\n",
       "\n",
       "[64 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_df.loc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Opinions on the Financial Statements and Internal Control over Financial Reporting'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df.loc[\"TSLA20230569\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
